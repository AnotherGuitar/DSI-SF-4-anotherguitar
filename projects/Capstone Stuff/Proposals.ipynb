{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Proposals:\n",
    "    \n",
    "As Americans, we have an enormous variety of foods commonly available at grocery stores, corner shops, and increasingly, online. For one project, I'd like to take a look at the fundamental ingredients and nutrients that compose this great variety. My hope would be to predict the number of nutrients found in certain food items, as well as looking hollistically at the ingredients that are most common in our foods. I would like to then relate this to general dietary habits of the US population, and get a granular idea of the nutrient composition of diets. The stretch goal would be to predict the changes in nutrient-use given an increasing population of vegans, where I could estimate increases in required nutrient needs based on 'normal' diets. I'm unsure whether this would be kosher, because obviously I can't check the quality of my predictions for the future. I could, however, see if I could predict correlations on historical data in growth of the vegan diet in the US, and then use that model to predict the effect of future growth of vegan diets.\n",
    "       \n",
    "*** (I'm still pondering the best way to go about this, but at least you can see where I'm hoping to take this) ***\n",
    "    \n",
    "'Nutrient Database from 2012' - https://catalog.data.gov/dataset/usda-national-nutrient-database-for-standard-reference\n",
    "'Nutrient Database from 2009' - https://catalog.data.gov/dataset/usda-national-nutrient-database-for-standard-reference-release-22\n",
    "    \n",
    "Partially pre-cleaned nutrient data - https://github.com/mhess126/usda_national_nutrients\n",
    "USDA API (not sure if this could be useful yet?) - https://ndb.nal.usda.gov/ndb/api/doc\n",
    "    \n",
    "    \n",
    "I'm still looking for better data to work with that could give me some idea of dietary habits, but here's where I've been looking - https://catalog.data.gov/dataset?q=bureauCode:%22005:13%22 ; https://catalog.data.gov/dataset?q=usda+consumption+national+nutrient&sort=views_recent+desc&ext_location=&ext_bbox=&ext_prev_extent=-142.03125%2C2.4601811810210052%2C-59.0625%2C58.63121664342478\n",
    "    \n",
    "    \n",
    "Alternatively, I could look at pricing these ingredients, based on the foodtypes that we find them in. For example, take a chili sauce. Of this sauce, take a look at the unique ingredients, and their respective portion size in the sauce. Let's say that black beans compose 20% of the chili, and the chili runs 5 dollars/unit. Then the pricing for the black bean ingredient would be 1 dollar.\n",
    "\n",
    "From there, I would want to observe how expensive these ingredients can get and how their prices change depending on what products they may be found in. \n",
    "    \n",
    "'Food Price Outlook, current' - https://catalog.data.gov/dataset/food-price-outlook\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pip install scrapy\n",
    "# pip install --upgrade zope2\n",
    "\n",
    "import foursquare\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "from scrapy import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import seaborn as sns\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLIENT_ID = '33NDJLQ342FAMTNX5Z55PR0PQQOJZRAZZ3XEAI0ERQXEJRUL'\n",
    "CLIENT_SECRET = 'FGMFNZGMWUR1ILZFGH2NV1OKQY3WK5AAPHWKXTFWRR3B4Z4E'\n",
    "client = foursquare.Foursquare(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-122.355079651\n",
      "[37.8127675576, 37.7078622611]\n",
      "360\n"
     ]
    }
   ],
   "source": [
    "#Let's define a geo dictionary whose bounds encompass all of SF, and another 4 miles south as well (so ~7mi x 11mi)\n",
    "ne = {'ne_lat': -122.3550796509, 'ne_long': 37.8127675576}\n",
    "sw = {'sw_lat': -122.5164413452, 'sw_long': 37.7078622611}\n",
    "\n",
    "# east/west\n",
    "lat_bounds = [ne['ne_lat'], sw['sw_lat']]\n",
    "print lat_bounds[0]\n",
    "# north/south\n",
    "lon_bounds = [ne['ne_long'], sw['sw_long']]\n",
    "print lon_bounds\n",
    "\n",
    "#increment ~ half a mile (in latitude/longitude), is 0.007\n",
    "increment = 0.007\n",
    "\n",
    "# The gridding below moves North, starting from the bottom SW corner boundary, and then moves east half a mile,\n",
    "# and repeats the process until stopping at the NE corner boundary.\n",
    "grid_pairs = []\n",
    "for lat in np.arange(lat_bounds[1], lat_bounds[0], increment):\n",
    "    for lon in np.arange(lon_bounds[1], lon_bounds[0], increment):\n",
    "        grid_pairs.append([lat, lon])\n",
    "        \n",
    "print len(grid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# should i make the loop above this cell more efficient by checking and storing which url's don't work?\n",
    "# B/C then I can exclude them the next time i run my loops ; BUT, it's probably better to keep track of these,\n",
    "# because while some won't even be eateries, many will be eateries that simply don't have foursqare menus.\n",
    "\n",
    "# In such cases, knowing the venue information could still be valuable, because we can surface those to users who\n",
    "# wish to manually add items (could possibly add items by taking pictures of the menu where the item is located)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here, I work with the Explore Endpoint\n",
    "\n",
    "# This will pull the venue names and url's (labeled as 'explored_venue_ids') that correspond to the geographical areas\n",
    "# I paired off in the previous step with grid_pairs. These are the  urls that I then intend to scrape in subsequent\n",
    "# steps.\n",
    "\n",
    "unique_venues_from_explore = []\n",
    "unique_venue_names_from_explore = []\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "for x, y in grid_pairs:\n",
    "    for offset in range(50, 251, 50):\n",
    "        try:\n",
    "            # Radius is radius in meters around given 'll'; 800 meters\n",
    "            # is approx 0.5 miles (but I may adjust the radius going forward)\n",
    "        \n",
    "            explore = client.venues.explore(params={'ll': '%.2f, %.2f' % (y, x), 'llAcc':'100.0','radius': '2000',\n",
    "                                               'section': 'food','limit':'50','offset':''+str(offset)+'',\n",
    "                                                    'sortByDistance':'1'})\n",
    "            explored_venue_ids = []\n",
    "            explored_venue_names = []\n",
    "\n",
    "            for i in range(len(explore['groups'][0]['items'])):\n",
    "                try:\n",
    "                    pulled_id = explore['groups'][0]['items'][i]['venue']['menu']['url']\n",
    "                    explored_venue_ids.append(pulled_id)\n",
    "                    pulled_name = explore['groups'][0]['items'][i]['venue']['name']\n",
    "                    explored_venue_names.append(pulled_name)\n",
    "                except:\n",
    "                    pass\n",
    "            for next_id, next_name in zip(explored_venue_ids, explored_venue_names):\n",
    "                if 'foursquare.com' in str(next_id):\n",
    "                    unique_venues_from_explore.append(next_id)\n",
    "                    unique_venue_names_from_explore.append(next_name)\n",
    "            counter += 1\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time)), \"loop number:\", counter\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987 1035\n"
     ]
    }
   ],
   "source": [
    "print len(unique_venue_names_from_explore), len(unique_venues_from_explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1035 48\n"
     ]
    }
   ],
   "source": [
    "unique_venues_from_explore = list(set(unique_venues_from_explore))\n",
    "unique_venue_names_from_explore = list(set(unique_venue_names_from_explore))\n",
    "unique_but_chained_venues = len(unique_venues_from_explore) - len(unique_venue_names_from_explore)\n",
    "\n",
    "print len(unique_venues_from_explore), unique_but_chained_venues\n",
    "# So ~ 18% of our results are unique venues (and another 48 of them are unique venus, but w/ the same name i.e. chains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that I have plenty of urls, let's plug them into a scraper so I can populate my df. Here are the headers\n",
    "# I'm looking to get as well...\n",
    "\n",
    "column_headers = ['venue_name', 'venue_desc_list', 'vegan_venue_check', 'venue_menu_url', 'venue_rated', 'meta_menu_n', 'depth_menus_n',\n",
    "                  'menu_item_name', 'menu_item_price', 'menu_item_desc']\n",
    "\n",
    "df_ready_rows = []\n",
    "def parse_url(url, data=False):\n",
    "\n",
    "    response               =  requests.get(url)\n",
    "    \n",
    "    #Steps:\n",
    "    #1) get the unicode objects\n",
    "    #2) change objects from unicode to string\n",
    "    \n",
    "    venue_name_uni         = Selector(text=response.text).xpath('//h1[@class=\"venueName\"]/text()').extract()\n",
    "    venue_name             = unicodedata.normalize('NFKD', venue_name_uni[0]).encode('ascii','ignore')\n",
    "    \n",
    "    # I also need to do an iteration to capture the multiple descriptors.\n",
    "    # I'll store the descriptors in a list to capture the entire description:\n",
    "    venue_desc_uni         =  Selector(text=response.text).xpath('//span[@class=\"unlinkedCategory\"]/\\\n",
    "    text()').extract()\n",
    "    venue_desc_list        = []\n",
    "    vegan_venue_check       = [] # I'll also do a quick check to see up front if we have a vegan menu on our hands\n",
    "    for venue_desc_phrase in range(len(venue_desc_uni)):\n",
    "        venue_desc_n       = unicodedata.normalize('NFKD', venue_desc_uni[venue_desc_phrase]).encode('ascii',\n",
    "                                                                                                  'ignore')\n",
    "        venue_desc_list.append(venue_desc_n)\n",
    "\n",
    "    flat_desc = ' '.join(venue_desc_list)\n",
    "    if 'vegetarian / vegan restaurant' in flat_desc.lower():\n",
    "        vegan_venue_check = 'vegan'\n",
    "    else:\n",
    "        vegan_venue_check = 'not_vegan'\n",
    "\n",
    "    # The url too, right?\n",
    "    venue_menu_url         = url\n",
    "\n",
    "    # Grabbing the venue rating, just a note: venueScore positive/neutral/negative, but I'm only getting the\n",
    "    # rating number, on a scale 1-10\n",
    "    venueScore_options     = ['positive','neutral','negative']\n",
    "    venue_rated = []\n",
    "    for vs_option in venueScore_options:\n",
    "        try:\n",
    "            venue_rating_uni        = Selector(text=response.text).xpath('//div[@class=\"venueRateBlock  \"]/\\\n",
    "    span[@class=\"venueScore '+vs_option+'\"]/span/text()').extract()\n",
    "            venue_rated             = unicodedata.normalize('NFKD', venue_rating_uni[0]).encode('ascii','ignore')\n",
    "            venue_rated = float(venue_rated)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    # Even if there is no rating, I'd still like to keep track of that...\n",
    "    if venue_rated == np.nan:\n",
    "        venue_rated = 'rating_not_available'\n",
    "        \n",
    "    #And I'll transform the list back into a string...\n",
    "#     venue_rated = venue_rated[0]\n",
    "    \n",
    "    #NOTE: do i also need to account for when menus don't have titles? because in that case meta_menu_list\n",
    "    #could/would\n",
    "    #return null. if so, perhaps just do a 'try excepct:pass' function if it can't find titles, but could it still\n",
    "    #grab the menu items? maybe i should just put in a \"null title\" for the meta_menu_n to overcome this\n",
    "    #I no longer think this is an issue, but maybe something to put in the appendix for later?\n",
    "    \n",
    "    meta_menu_list      =  Selector(text=response.text).xpath('//h2[@class=\"categoryName\"]/text()').extract()\n",
    "        \n",
    "    for meta_menu_item in range(len(meta_menu_list)):\n",
    "        \n",
    "        meta_menu_n         = unicodedata.normalize('NFKD', meta_menu_list[meta_menu_item]).encode('ascii',\n",
    "                                                                                                   'ignore')\n",
    "        \n",
    "#         print \"meta menu title %d:\" %(meta_menu_item+1), meta_menu_n, \"# of meta menus:\", len(meta_menu_list)\n",
    "        \n",
    "        depth_menus_n_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]['+str(meta_menu_item+1)+']/\\\n",
    "        div[@class=\"menuItems\"]/div[@class=\"section\"]/div[@class=\"sectionHeader\"]/\\\n",
    "        div[@class=\"sectionName\"]/text()').extract()\n",
    "        \n",
    "        for meta_depth_nn in range(len(depth_menus_n_uni)):\n",
    "            \n",
    "            depth_menus_n     = unicodedata.normalize('NFKD', depth_menus_n_uni[meta_depth_nn]\n",
    "                                                     ).encode('ascii','ignore')\n",
    "\n",
    "            #get the name of the depth menu, and record it's location as 'n_level'\n",
    "            n_level = meta_depth_nn+1\n",
    "#             print \"depth menu title %d:\" %(n_level), depth_menus_n\n",
    "            \n",
    "            #let's grab the entire depth menu:\n",
    "            depth_menu_id_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]\\\n",
    "            ['+str(meta_menu_item+1)+']/div[@class=\"menuItems\"]/div[@class=\"section\"]['+str(n_level)+']/\\\n",
    "            div[@class=\"sectionHeader\"]/div[@class=\"sectionName\"]/text()').extract()\n",
    "            depth_menu_id     = unicodedata.normalize('NFKD', depth_menu_id_uni[0]\n",
    "                                                     ).encode('ascii','ignore')\n",
    "            depth_menu_id = len(depth_menu_id_uni)\n",
    "#             print \"#id of depth menu:\", depth_menu_id\n",
    "            \n",
    "            #loop throught the left and right side of each container:\n",
    "            left_or_right_list = ['left','right']\n",
    "            \n",
    "            for left_or_right in left_or_right_list:\n",
    "    \n",
    "                #need the length of the [left/right] container, to iterate through:\n",
    "                container_len_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]\\\n",
    "                ['+str(meta_menu_item+1)+']/div[@class=\"menuItems\"]/div[@class=\"section\"]['+str(n_level)+']/div\\\n",
    "                [@class=\"entryContainer\"]/div[@class=\"'+left_or_right+'Column\"]/\\\n",
    "                div[@class=\"entry\"]/node()[1]//text()').extract()\n",
    "#                 print \"left_check:\", left_or_right, \"contain len:\", len(container_len_uni)\n",
    "            \n",
    "                for section_n in range(len(container_len_uni)):                    \n",
    "                    \n",
    "                    #now we can get the name of that menu item...\n",
    "                    menu_item_name_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]\\\n",
    "                    ['+str(meta_menu_item+1)+']/div[@class=\"menuItems\"]/div[@class=\"section\"]\\\n",
    "                    ['+str(n_level)+']/div\\\n",
    "                    [@class=\"entryContainer\"]/div[@class=\"'+left_or_right+'Column\"]/div[@class=\"entry\"]\\\n",
    "                    ['+str(section_n+1)+']/node()[1]//text()').extract()\n",
    "                    menu_item_name     = unicodedata.normalize('NFKD', menu_item_name_uni[0]\n",
    "                                                                    ).encode('ascii','ignore')\n",
    "#                     print \"menu_item_name:\", menu_item_name\n",
    "                    \n",
    "                    #and then we can get the price (if there is one...)\n",
    "                    try:\n",
    "                        menu_item_price_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]\\\n",
    "                    ['+str(meta_menu_item+1)+']/div[@class=\"menuItems\"]/div[@class=\"section\"]\\\n",
    "                    ['+str(n_level)+']/div\\\n",
    "                    [@class=\"entryContainer\"]/div[@class=\"'+left_or_right+'Column\"]/div[@class=\"entry\"]\\\n",
    "                    ['+str(section_n+1)+']/node()[2]//text()').extract()\n",
    "                        menu_item_price     = unicodedata.normalize('NFKD', menu_item_price_uni[0]\n",
    "                                                                    ).encode('ascii','ignore')\n",
    "                        menu_item_price = float(menu_item_price)\n",
    "#                         print \"menu_item_price:\", menu_item_price\n",
    "                    except:\n",
    "#                         print \"menu_item_price:\", \"price_not_available\"\n",
    "                        menu_item_price = 'price_not_available'\n",
    "                    \n",
    "                    #and finally the description (if there is one...)\n",
    "                    try:\n",
    "                        menu_item_desc_uni = Selector(text=response.text).xpath('//div[@class=\"menu\"]\\\n",
    "                    ['+str(meta_menu_item+1)+']/div[@class=\"menuItems\"]/div[@class=\"section\"]\\\n",
    "                    ['+str(n_level)+']/div\\\n",
    "                    [@class=\"entryContainer\"]/div[@class=\"'+left_or_right+'Column\"]/div[@class=\"entry\"]\\\n",
    "                    ['+str(section_n+1)+']/node()[3]//text()').extract()\n",
    "                        menu_item_desc     = unicodedata.normalize('NFKD', menu_item_desc_uni[0]\n",
    "                                                                    ).encode('ascii','ignore')\n",
    "#                         print \"menu_item_desc:\", menu_item_desc\n",
    "                    except:\n",
    "#                         print \"menu_item_desc:\", \"desc_not_available\"\n",
    "                        menu_item_desc = 'desc_not_available'\n",
    "\n",
    "                    # Finally, I'll append my results so that when I wrap up the fuction, I can finish with\n",
    "                    # a prepared set of info, dataframe ready.\n",
    "                    df_ready_rows.append([venue_name,\n",
    "                                          venue_desc_list,\n",
    "                                          vegan_venue_check,\n",
    "                                          venue_menu_url,\n",
    "                                          venue_rated,\n",
    "                                          meta_menu_n,\n",
    "                                          depth_menus_n,\n",
    "                                          menu_item_name,\n",
    "                                          menu_item_price,\n",
    "                                          menu_item_desc])\n",
    "    return df_ready_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Actually, through the Explore endpoint, I was able to directly grab the menu url, so no need to manually build my\n",
    "# url this time...\n",
    "start_time = time.time()\n",
    "countered = 0\n",
    "for menu_url in unique_venues_from_explore:\n",
    "    try:\n",
    "        parse_url(menu_url)\n",
    "    except:\n",
    "        pass\n",
    "    countered += 1\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time)), \"loop number:\", countered\n",
    "#Takes about 4 mins for 30 url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90140\n"
     ]
    }
   ],
   "source": [
    "print len(df_ready_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90140, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_endpoint_df = pd.DataFrame(df_ready_rows, columns=column_headers)\n",
    "explore_endpoint_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I ran my script previously, and just saved a local copy...\n",
    "# explore_endpoint_df.to_pickle('../../projects/Capstone Stuff/explore_endpoint_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "explore_endpoint_df = pd.read_pickle('../../projects/Capstone Stuff/explore_endpoint_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(explore_endpoint_df.venue_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_vegan    88279\n",
       "vegan         1861\n",
       "Name: vegan_venue_check, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_endpoint_df.vegan_venue_check.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_desc_list</th>\n",
       "      <th>vegan_venue_check</th>\n",
       "      <th>venue_menu_url</th>\n",
       "      <th>venue_rated</th>\n",
       "      <th>meta_menu_n</th>\n",
       "      <th>depth_menus_n</th>\n",
       "      <th>menu_item_name</th>\n",
       "      <th>menu_item_price</th>\n",
       "      <th>menu_item_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home Plate</td>\n",
       "      <td>[Diner, Breakfast Spot, Comfort Food Restaurant]</td>\n",
       "      <td>not_vegan</td>\n",
       "      <td>https://foursquare.com/v/home-plate/4a9ec745f9...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Soups &amp; Salads</td>\n",
       "      <td>Soup Du Jour</td>\n",
       "      <td>3.5</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home Plate</td>\n",
       "      <td>[Diner, Breakfast Spot, Comfort Food Restaurant]</td>\n",
       "      <td>not_vegan</td>\n",
       "      <td>https://foursquare.com/v/home-plate/4a9ec745f9...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Soups &amp; Salads</td>\n",
       "      <td>Caesar Salad</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Romaine lettuce, freshly grated parmesan cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home Plate</td>\n",
       "      <td>[Diner, Breakfast Spot, Comfort Food Restaurant]</td>\n",
       "      <td>not_vegan</td>\n",
       "      <td>https://foursquare.com/v/home-plate/4a9ec745f9...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Soups &amp; Salads</td>\n",
       "      <td>Grilled Shrimp Salad</td>\n",
       "      <td>8.25</td>\n",
       "      <td>Oranges, cashews and citrus vinaigrett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home Plate</td>\n",
       "      <td>[Diner, Breakfast Spot, Comfort Food Restaurant]</td>\n",
       "      <td>not_vegan</td>\n",
       "      <td>https://foursquare.com/v/home-plate/4a9ec745f9...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Soups &amp; Salads</td>\n",
       "      <td>House Salad</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Spring mix, tomatoes, carrots, balsamic vinaig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home Plate</td>\n",
       "      <td>[Diner, Breakfast Spot, Comfort Food Restaurant]</td>\n",
       "      <td>not_vegan</td>\n",
       "      <td>https://foursquare.com/v/home-plate/4a9ec745f9...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Soups &amp; Salads</td>\n",
       "      <td>Cobb Salad</td>\n",
       "      <td>7.95</td>\n",
       "      <td>Chicken, avocado, applewood smoked bacon, egg,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   venue_name                                   venue_desc_list  \\\n",
       "0  Home Plate  [Diner, Breakfast Spot, Comfort Food Restaurant]   \n",
       "1  Home Plate  [Diner, Breakfast Spot, Comfort Food Restaurant]   \n",
       "2  Home Plate  [Diner, Breakfast Spot, Comfort Food Restaurant]   \n",
       "3  Home Plate  [Diner, Breakfast Spot, Comfort Food Restaurant]   \n",
       "4  Home Plate  [Diner, Breakfast Spot, Comfort Food Restaurant]   \n",
       "\n",
       "  vegan_venue_check                                     venue_menu_url  \\\n",
       "0         not_vegan  https://foursquare.com/v/home-plate/4a9ec745f9...   \n",
       "1         not_vegan  https://foursquare.com/v/home-plate/4a9ec745f9...   \n",
       "2         not_vegan  https://foursquare.com/v/home-plate/4a9ec745f9...   \n",
       "3         not_vegan  https://foursquare.com/v/home-plate/4a9ec745f9...   \n",
       "4         not_vegan  https://foursquare.com/v/home-plate/4a9ec745f9...   \n",
       "\n",
       "   venue_rated meta_menu_n   depth_menus_n        menu_item_name  \\\n",
       "0          8.9   Main Menu  Soups & Salads          Soup Du Jour   \n",
       "1          8.9   Main Menu  Soups & Salads          Caesar Salad   \n",
       "2          8.9   Main Menu  Soups & Salads  Grilled Shrimp Salad   \n",
       "3          8.9   Main Menu  Soups & Salads           House Salad   \n",
       "4          8.9   Main Menu  Soups & Salads            Cobb Salad   \n",
       "\n",
       "  menu_item_price                                     menu_item_desc  \n",
       "0             3.5                                 desc_not_available  \n",
       "1             5.5    Romaine lettuce, freshly grated parmesan cheese  \n",
       "2            8.25             Oranges, cashews and citrus vinaigrett  \n",
       "3             4.5  Spring mix, tomatoes, carrots, balsamic vinaig...  \n",
       "4            7.95  Chicken, avocado, applewood smoked bacon, egg,...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_endpoint_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some tom-foolery w/ regards to the explore_endpoint_df is below, before my final notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 [2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804]\n"
     ]
    }
   ],
   "source": [
    "# Here I'm just testing out a prototype search function\n",
    "count = 0\n",
    "loc_list = []\n",
    "for i in range(explore_endpoint_df.shape[0]):\n",
    "    flat_desc = ' '.join(explore_endpoint_df.venue_desc_list[i])\n",
    "    if 'american' in flat_desc.lower():\n",
    "        count += 1\n",
    "        loc_list.append(i)\n",
    "print count, loc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_desc_list</th>\n",
       "      <th>venue_menu_url</th>\n",
       "      <th>venue_rated</th>\n",
       "      <th>meta_menu_n</th>\n",
       "      <th>depth_menus_n</th>\n",
       "      <th>menu_item_name</th>\n",
       "      <th>menu_item_price</th>\n",
       "      <th>menu_item_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>Underdog</td>\n",
       "      <td>[Hot Dog Joint, American Restaurant, Vegetaria...</td>\n",
       "      <td>https://foursquare.com/v/underdog/49d00adcf964...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Catering Menu</td>\n",
       "      <td>Organic Condiments</td>\n",
       "      <td>Dijon Mustard</td>\n",
       "      <td>5</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     venue_name                                    venue_desc_list  \\\n",
       "2804   Underdog  [Hot Dog Joint, American Restaurant, Vegetaria...   \n",
       "\n",
       "                                         venue_menu_url  venue_rated  \\\n",
       "2804  https://foursquare.com/v/underdog/49d00adcf964...          8.0   \n",
       "\n",
       "        meta_menu_n       depth_menus_n menu_item_name menu_item_price  \\\n",
       "2804  Catering Menu  Organic Condiments  Dijon Mustard               5   \n",
       "\n",
       "          menu_item_desc  \n",
       "2804  desc_not_available  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in loc_list:\n",
    "    dffff = explore_endpoint_df.loc[[i]]\n",
    "dffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below is an alternate approach, using the Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This will independently pull the venue names and id codes that correspond to the geographical areas\n",
    "# I paired off in the previous step with grid_pairs. The names and id's will be subesquently used to\n",
    "# construct menu url's, which I then intend to scrape.\n",
    "\n",
    "unique_venues_from_search = []\n",
    "unique_venue_names_from_search = []\n",
    "start_time = time.time()\n",
    "\n",
    "for x, y in grid_pairs:\n",
    "    try:\n",
    "        search = client.venues.search(params={'ll': '%.2f, %.2f' % (y, x),'query': 'food', 'limit':'50',\n",
    "                                      'intent':'browse','radius':'800'})\n",
    "        searched_venue_ids = [search['venues'][i]['id'] for i in range(len(search['venues']))]\n",
    "        searched_name_ids = [search['venues'][i]['name'] for i in range(len(search['venues']))]\n",
    "        for next_id, next_name in zip(searched_venue_ids, searched_name_ids):\n",
    "            unique_venues_from_search.append(next_id)\n",
    "            unique_venue_names_from_search.append(next_name)\n",
    "#         print('--- %s loop-active seconds ---' % (time.time() - start_time))\n",
    "    except:\n",
    "        print('Sleeping...')\n",
    "#         time.sleep(random.randint(115,140))\n",
    "print('--- %s active seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 358\n"
     ]
    }
   ],
   "source": [
    "print len(unique_venue_names_from_search), len(unique_venues_from_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'Food Fair',\n",
       "  u'Food Fair',\n",
       "  u'Asian American Food Company',\n",
       "  u'Other Avenues Food Store',\n",
       "  u'7-Eleven'],\n",
       " [u'4e3d8765ae60454236667cc4',\n",
       "  u'4e3d8765ae60454236667cc4',\n",
       "  u'463bfdccf964a52026461fe3',\n",
       "  u'4a90954ff964a520a61820e3',\n",
       "  u'4afba001f964a520d51e22e3'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_venue_names_from_search[:5], unique_venues_from_search[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will only work for the Search Endpoint\n",
    "menu_urls_from_search = []\n",
    "base_url = 'https://foursquare.com/v/'\n",
    "for venue_id, venue_name in zip(unique_venues_from_search, unique_venue_names_from_search):\n",
    "    dat_id = unicodedata.normalize('NFKD', venue_id).encode('ascii','ignore')\n",
    "    dat_name = unicodedata.normalize('NFKD', venue_name).encode('ascii','ignore')\n",
    "    dat_name = dat_name.lower().replace('/','-').replace(' ','-')\n",
    "    transformed_url = base_url+dat_name+'/'+dat_id+'/menu'\n",
    "    menu_urls_from_search.append(transformed_url)\n",
    "len(menu_urls_from_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing that no venues have been duplicated with my searches\n",
    "unique_urls_from_search = list(set(menu_urls_from_search))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_urls_from_search)\n",
    "#This amounts to roughly 8% of my total venues searched i.e. 280/(70*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.49055480957 seconds ---\n",
      "--- 12.5686228275 seconds ---\n",
      "--- 12.7575688362 seconds ---\n",
      "--- 12.9671459198 seconds ---\n",
      "--- 13.1560468674 seconds ---\n",
      "--- 13.3051497936 seconds ---\n",
      "--- 25.0519609451 seconds ---\n",
      "--- 25.3167629242 seconds ---\n",
      "--- 25.493188858 seconds ---\n",
      "--- 37.2827179432 seconds ---\n",
      "--- 37.6100490093 seconds ---\n",
      "--- 52.5052340031 seconds ---\n",
      "--- 52.6898667812 seconds ---\n",
      "--- 53.4898679256 seconds ---\n",
      "--- 62.1172599792 seconds ---\n",
      "--- 64.9277229309 seconds ---\n",
      "--- 65.1554119587 seconds ---\n",
      "--- 77.1680719852 seconds ---\n",
      "--- 77.3154718876 seconds ---\n",
      "--- 77.5070137978 seconds ---\n",
      "--- 89.2520778179 seconds ---\n",
      "--- 89.5217859745 seconds ---\n",
      "--- 89.6632127762 seconds ---\n",
      "--- 89.8353009224 seconds ---\n",
      "--- 90.3072829247 seconds ---\n",
      "--- 90.7108669281 seconds ---\n",
      "--- 101.565645933 seconds ---\n",
      "--- 101.976698875 seconds ---\n",
      "--- 113.615211964 seconds ---\n",
      "--- 113.790491819 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Could be not working because they don't have a menu, or because they're not a restaurant. So could be useful to\n",
    "# later determine if they are or aren't restaurants to begin with\n",
    "start_time = time.time()\n",
    "for menu_url in unique_urls_from_search[:30]:\n",
    "    try:\n",
    "        parse_url(menu_url)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_endpoint_df = pd.DataFrame(df_ready_rows, columns=column_headers)\n",
    "search_endpoint_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in search_endpoint_df.venue_desc_list:\n",
    "    if 'vegan' in j[0]:\n",
    "        print \"vegans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>venue_name</th>\n",
       "      <th>venue_desc_list</th>\n",
       "      <th>venue_menu_url</th>\n",
       "      <th>venue_rated</th>\n",
       "      <th>meta_menu_n</th>\n",
       "      <th>depth_menus_n</th>\n",
       "      <th>menu_item_name</th>\n",
       "      <th>menu_item_price</th>\n",
       "      <th>menu_item_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victor's</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>https://foursquare.com/v/victor's/4a898fc8f964...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Tacos</td>\n",
       "      <td>Beef Or Grilled Chicken</td>\n",
       "      <td>2.65</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Victor's</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>https://foursquare.com/v/victor's/4a898fc8f964...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Tacos</td>\n",
       "      <td>Chile Verde Or Pork</td>\n",
       "      <td>2.65</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Victor's</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>https://foursquare.com/v/victor's/4a898fc8f964...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Tacos</td>\n",
       "      <td>Chicken Mole</td>\n",
       "      <td>2.65</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victor's</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>https://foursquare.com/v/victor's/4a898fc8f964...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Tacos</td>\n",
       "      <td>Nachos</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Cheese, salsa, sour cream, refried beans, grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Victor's</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>https://foursquare.com/v/victor's/4a898fc8f964...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Main Menu</td>\n",
       "      <td>Tortas</td>\n",
       "      <td>Beef Or Grilled Chicken</td>\n",
       "      <td>5.7</td>\n",
       "      <td>desc_not_available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  venue_name       venue_desc_list  \\\n",
       "0   Victor's  [Mexican Restaurant]   \n",
       "1   Victor's  [Mexican Restaurant]   \n",
       "2   Victor's  [Mexican Restaurant]   \n",
       "3   Victor's  [Mexican Restaurant]   \n",
       "4   Victor's  [Mexican Restaurant]   \n",
       "\n",
       "                                      venue_menu_url  venue_rated meta_menu_n  \\\n",
       "0  https://foursquare.com/v/victor's/4a898fc8f964...          7.5   Main Menu   \n",
       "1  https://foursquare.com/v/victor's/4a898fc8f964...          7.5   Main Menu   \n",
       "2  https://foursquare.com/v/victor's/4a898fc8f964...          7.5   Main Menu   \n",
       "3  https://foursquare.com/v/victor's/4a898fc8f964...          7.5   Main Menu   \n",
       "4  https://foursquare.com/v/victor's/4a898fc8f964...          7.5   Main Menu   \n",
       "\n",
       "  depth_menus_n           menu_item_name menu_item_price  \\\n",
       "0         Tacos  Beef Or Grilled Chicken            2.65   \n",
       "1         Tacos      Chile Verde Or Pork            2.65   \n",
       "2         Tacos             Chicken Mole            2.65   \n",
       "3         Tacos                   Nachos             1.5   \n",
       "4        Tortas  Beef Or Grilled Chicken             5.7   \n",
       "\n",
       "                                      menu_item_desc  \n",
       "0                                 desc_not_available  \n",
       "1                                 desc_not_available  \n",
       "2                                 desc_not_available  \n",
       "3  Cheese, salsa, sour cream, refried beans, grou...  \n",
       "4                                 desc_not_available  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_endpoint_df.loc[:50[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"https://foursquare.com/v/victor's/4a898fc8f964a520660820e3/menu\",\n",
       "       'https://foursquare.com/v/artesano/51e0ad55498eb7f2b6ed10e2/menu'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_endpoint_df.venue_menu_url.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BELOW ARE POTENTIALLY USEFUL, BUT UNUSED MATERIAL::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will be the func to add the next offset to my completed venue list...\n",
    "def extend_unique_venues(unique_venues, proposed_venue):\n",
    "    if proposed_venue not in unique_venues:\n",
    "        unique_venues.append(proposed_venue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Category/column titles, in order:\n",
    "# # [venue_name, venue_desc_list, venue_menu_url, venue_rated], [meta_menu_n], [depth_menus_n], [menu_item_name,\n",
    "# # menu_item_price, menu_item_desc]\n",
    "\n",
    "# venue_rows = []\n",
    "# for [venue_name, venue_desc_list, venue_menu_url, venue_rated] in venues: \n",
    "#     for meta_menu in meta_menu_n:\n",
    "#         for depth_menu in depth_menus_n:\n",
    "#             venue_rows.append([venue_name,\n",
    "#                                venue_desc_list,\n",
    "#                                venue_rated,\n",
    "#                                meta_menu,\n",
    "#                                depth_menu,\n",
    "#                                menu_item_name,\n",
    "#                                menu_item_price,\n",
    "#                                menu_item_desc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Category/column titles, in order:\n",
    "# # [venue_name, venue_desc_list, venue_menu_url, venue_rated], [meta_menu_n], [depth_menus_n], [menu_item_name,\n",
    "# # menu_item_price, menu_item_desc]\n",
    "\n",
    "# venue_dict = {}\n",
    "# for [venue_name, venue_desc_list, venue_menu_url, venue_rated] in venues:\n",
    "#     venue_dict[venue_name] = {'desc_list':venue_desc_list,\n",
    "#                               'menu_url':venue_menu_url,\n",
    "#                               'rating':venue_rated}\n",
    "    \n",
    "#     for meta_menu in meta_menu_n:\n",
    "#         venue_dict[venue_name][meta_menu] = {}\n",
    "            \n",
    "#         for depth_menu in depth_menus_n:\n",
    "#             venue_dict[venue_name][meta_menu][depth_menu] = {'menu_item_name':menu_item_name,\n",
    "#                                                              'menu_item_price':menu_item_price,\n",
    "#                                                              'menu_item_desc':menu_item_desc}\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # If for some reason I find it easier to work with category id's from API calls, I can use this block:\n",
    "# # So for instance, I can say that if pulled_id == '4bf58dd8d48988d1d3941735', append('vegan') or append(1),\n",
    "# # and that could easily serve as my target to predict on\n",
    "\n",
    "# explore = client.venues.explore(params={'ll': '%.2f, %.2f' % (37.8127675576, -122.3550796509),\n",
    "#                                         'llAcc':'100.0','radius': '6000',\n",
    "#                                         'section': 'food','limit':'50','offset':'50','sortByDistance':'1'})\n",
    "# pulled_id = explore['groups'][0]['items'][10]['venue']['categories'][0]['id']\n",
    "# print pulled_id"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
